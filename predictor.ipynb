{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import yaml\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from datasets import *\n",
    "from nets import *\n",
    "from functions import *\n",
    "from trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train/train-faces/F0911/MID1/P09623_face0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train/train-faces/F0782/MID1/P08258_face4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train/train-faces/F0232/MID2/P02462_face0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train/train-faces/F0089/MID1/P00918_face0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train/train-faces/F0639/MID5/P06711_face0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12161</th>\n",
       "      <td>Train/train-faces/F0425/MID8/P11471_face6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12162</th>\n",
       "      <td>Train/train-faces/F0601/MID20/P11953_face2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12163</th>\n",
       "      <td>Train/train-faces/F0601/MID2/P06274_face2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12164</th>\n",
       "      <td>Train/train-faces/F0601/MID9/P06244_face1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>Train/train-faces/F0987/MID13/P10402_face10.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12166 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filename\n",
       "0        Train/train-faces/F0911/MID1/P09623_face0.jpg\n",
       "1        Train/train-faces/F0782/MID1/P08258_face4.jpg\n",
       "2        Train/train-faces/F0232/MID2/P02462_face0.jpg\n",
       "3        Train/train-faces/F0089/MID1/P00918_face0.jpg\n",
       "4        Train/train-faces/F0639/MID5/P06711_face0.jpg\n",
       "...                                                ...\n",
       "12161    Train/train-faces/F0425/MID8/P11471_face6.jpg\n",
       "12162   Train/train-faces/F0601/MID20/P11953_face2.jpg\n",
       "12163    Train/train-faces/F0601/MID2/P06274_face2.jpg\n",
       "12164    Train/train-faces/F0601/MID9/P06244_face1.jpg\n",
       "12165  Train/train-faces/F0987/MID13/P10402_face10.jpg\n",
       "\n",
       "[12166 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/fiw_labels.txt', sep=' ', header=None, names=['index', 'filename', 'filename2', 'kt', 'gt'])\n",
    "df = df.drop(['index', 'filename2', 'kt', 'gt'], axis=1).drop_duplicates()\n",
    "df.to_csv('fiw_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config', type=str, default='001', help='path to the config file.')\n",
    "parser.add_argument('--vgg_model_path', type=str, default='./models/dex_imdb_wiki.caffemodel.pt', help='pretrained age classifier')\n",
    "parser.add_argument('--log_path', type=str, default='./logs/', help='log file path')\n",
    "parser.add_argument('--multigpu', type=bool, default=False, help='use multiple gpus')\n",
    "parser.add_argument('--checkpoint', type=str, default='', help='checkpoint file path')\n",
    "parser.add_argument('--img_path', type=str, default='./test/input/', help='test image path')\n",
    "parser.add_argument('--out_path', type=str, default='./test/output/', help='test output path')\n",
    "parser.add_argument('--target_age', type=int, default=55, help='Age transform target, interger value between 20 and 70')\n",
    "opts = parser.parse_known_args()[0]\n",
    "\n",
    "log_dir = os.path.join(opts.log_path, opts.config) + '/'\n",
    "if not os.path.exists(opts.out_path):\n",
    "    os.makedirs(opts.out_path)\n",
    "\n",
    "config = yaml.safe_load(open('./configs/' + opts.config + '.yaml', 'r'))\n",
    "img_size = (config['input_w'], config['input_h'])\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(config)\n",
    "device = torch.device('cuda')\n",
    "trainer.to(device)\n",
    "\n",
    "# Load pretrained model \n",
    "if opts.checkpoint:\n",
    "    trainer.load_checkpoint(opts.checkpoint)\n",
    "else:\n",
    "    trainer.load_checkpoint(log_dir + 'checkpoint')\n",
    "\n",
    "def preprocess(img_name):\n",
    "    resize = transforms.Compose([\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "    normalize = transforms.Normalize(mean=[0.48501961, 0.45795686, 0.40760392], std=[1,1,1])\n",
    "    img_pil = Image.open(opts.img_path + img_name)\n",
    "    img_np = np.array(img_pil)\n",
    "    img = resize(img_pil)\n",
    "    if img.size(0) == 1:\n",
    "        img = torch.cat((img, img, img), dim = 0)\n",
    "    img = normalize(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_age = 60\n",
    "\n",
    "target_image = '48517.png'\n",
    "\n",
    "with torch.no_grad():\n",
    "    img = preprocess(target_image).unsqueeze(0).to(device)\n",
    "\n",
    "    age_modif = torch.tensor(target_age).unsqueeze(0).to(device)\n",
    "    img_modif = trainer.test_eval(img, age_modif, target_age=target_age, hist_trans=True)  \n",
    "    utils.save_image(clip_img(img_modif), opts.out_path + target_image.split('.')[0] + '_age_' + str(target_age) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be PIL Image or ndarray. Got <class 'str'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img_name \u001b[38;5;129;01min\u001b[39;00m img_list:\n\u001b[0;32m---> 10\u001b[0m         image_A \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         image_A \u001b[38;5;241m=\u001b[39m image_A\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m         age_modif \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(target_age)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/mnt/heavy/miniconda3/envs/tcc/lib/python3.10/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/mnt/heavy/miniconda3/envs/tcc/lib/python3.10/site-packages/torchvision/transforms/transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/heavy/miniconda3/envs/tcc/lib/python3.10/site-packages/torchvision/transforms/functional.py:142\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    140\u001b[0m     _log_api_usage_once(to_tensor)\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (F_pil\u001b[38;5;241m.\u001b[39m_is_pil_image(pic) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy(pic)):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be PIL Image or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_numpy(pic) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_numpy_image(pic):\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be 2/3 dimensional. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpic\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be PIL Image or ndarray. Got <class 'str'>"
     ]
    }
   ],
   "source": [
    "# Set target age\n",
    "target_age = 60\n",
    "\n",
    "# Load test image\n",
    "img_list = os.listdir(opts.img_path)\n",
    "img_list.sort()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in img_list:\n",
    "        image_A = preprocess(img_name)\n",
    "        image_A = image_A.unsqueeze(0).to(device)\n",
    "\n",
    "        age_modif = torch.tensor(target_age).unsqueeze(0).to(device)\n",
    "        image_A_modif = trainer.test_eval(image_A, age_modif, target_age=target_age, hist_trans=True)  \n",
    "        utils.save_image(clip_img(image_A_modif), opts.out_path + img_name.split('.')[0] + '_age_' + str(target_age) + '.jpg')\n",
    "\n",
    "        # Plot manipulated image\n",
    "        img_out = np.array(Image.open(opts.out_path + img_name.split('.')[0] + '_age_' + str(target_age) + '.jpg'))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img_out)\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>id</th>\n",
       "      <th>year_taken</th>\n",
       "      <th>rank</th>\n",
       "      <th>lfw</th>\n",
       "      <th>birth</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>53_Robin_Williams_0001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>53_Robin_Williams_0002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>53_Robin_Williams_0003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>53_Robin_Williams_0004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>53_Robin_Williams_0005.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163441</th>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>23_Katie_Findlay_0009.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163442</th>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>23_Katie_Findlay_0010.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163443</th>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>23_Katie_Findlay_0011.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163444</th>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>23_Katie_Findlay_0012.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163445</th>\n",
       "      <td>23</td>\n",
       "      <td>2000</td>\n",
       "      <td>2013</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>23_Katie_Findlay_0013.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163446 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    id  year_taken  rank  lfw  birth                        name\n",
       "0        53     1        2004     1    1   1951  53_Robin_Williams_0001.jpg\n",
       "1        53     1        2004     1    1   1951  53_Robin_Williams_0002.jpg\n",
       "2        53     1        2004     1    1   1951  53_Robin_Williams_0003.jpg\n",
       "3        53     1        2004     1    1   1951  53_Robin_Williams_0004.jpg\n",
       "4        53     1        2004     1    1   1951  53_Robin_Williams_0005.jpg\n",
       "...     ...   ...         ...   ...  ...    ...                         ...\n",
       "163441   23  2000        2013    50    0   1990   23_Katie_Findlay_0009.jpg\n",
       "163442   23  2000        2013    50    0   1990   23_Katie_Findlay_0010.jpg\n",
       "163443   23  2000        2013    50    0   1990   23_Katie_Findlay_0011.jpg\n",
       "163444   23  2000        2013    50    0   1990   23_Katie_Findlay_0012.jpg\n",
       "163445   23  2000        2013    50    0   1990   23_Katie_Findlay_0013.jpg\n",
       "\n",
       "[163446 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nets import *\n",
    "from functions import *\n",
    "import pandas as pd\n",
    "\n",
    "CACD_PATH = '/mnt/heavy/DeepLearning/Datasets/CACD2000/'\n",
    "\n",
    "age_classifier = VGG()\n",
    "cacd = pd.read_csv(CACD_PATH + 'celebrity2000_meta.csv')\n",
    "cacd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age(path):\n",
    "    img = Image.open(CACD_PATH + '53_Robin_Williams_0001.jpg')\n",
    "\n",
    "    # Preprocess the image\n",
    "    preprocess = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.48501961, 0.45795686, 0.40760392], std=[1, 1, 1]),\n",
    "            ])\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    predict_age_pb = age_classifier(vgg_transform(img_tensor))['fc8']\n",
    "\n",
    "    # Get predicted age\n",
    "    predict_age = get_predict_age(predict_age_pb)\n",
    "    print(predict_age)\n",
    "    return int(predict_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49.9818], grad_fn=<CopySlices>)\n",
      "tensor([49.9818], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49.9818], grad_fn=<CopySlices>)\n",
      "tensor([49.9818], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([49.9818], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "ages = []\n",
    "# iterrows with tqdm\n",
    "for i, row in tqdm.tqdm(cacd.head(5).iterrows()):\n",
    "    ages.append(get_age(row['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 49]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
